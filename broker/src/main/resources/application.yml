micronaut:
  application:
    name: messaging-broker
  server:
    port: ${HTTP_PORT:8082}  # HTTP admin port

  metrics:
    enabled: true
    export:
      prometheus:
        enabled: true
        step: PT1M  # 1 minute scrape interval
        descriptions: true
    binders:
      jvm:
        enabled: true
      processor:
        enabled: true
      uptime:
        enabled: true
      files:
        enabled: true
      logback:
        enabled: true

endpoints:
  all:
    enabled: true
    sensitive: false
  prometheus:
    enabled: true
    sensitive: false
  health:
    enabled: true
    sensitive: false
  metrics:
    enabled: true
    sensitive: false

broker:
  nodeId: ${NODE_ID:local-001}

  registry:
    url: ${REGISTRY_URL:http://localhost:8080}

  storage:
    type: filechannel  # FileChannel-based (no mmap) for true zero-copy via sendfile()
    dataDir: ${DATA_DIR:/Users/anuragmishra/Desktop/workspace/messaging/data/}
    segment-size: 1073741824  # 1GB

  default-topic: ${DEFAULT_TOPIC:default-topic}

  network:
    type: tcp
    port: ${BROKER_PORT:19092}
    threads:
      boss: 2
      worker: 16

  consumer:
    default-retry-policy: EXPONENTIAL_THEN_FIXED
    default-max-exponential-retries: 10
    default-initial-retry-delay: 1000
    default-max-retry-delay: 30000
    default-fixed-retry-interval: 30000
    ack-timeout: 5000
    max-message-size-per-consumer: ${MAX_MESSAGE_SIZE_PER_CONSUMER:1048576}  # 1MB max data per consumer per delivery cycle
    # DEPRECATED: max-batch-size-per-consumer no longer used (size-only batching now)
    # max-batch-size-per-consumer: ${MAX_BATCH_SIZE_PER_CONSUMER:100}

    # Adaptive polling configuration (watermark-based delivery)
    adaptive-polling:
      min-delay-ms: 1          # Immediate poll when data found (near-push latency)
      max-delay-ms: 1000       # Max backoff delay when idle (exponential backoff)

    # Per-topic fairness configuration
    fairness:
      max-in-flight-per-topic: 4  # Max concurrent deliveries per topic (prevents hot topics from starving quiet ones)

# DataRefresh Configuration
# Expected consumers list for data refresh workflow using "group:topic" format
# This is stable across reconnections (unlike socket addresses which are dynamic)
data-refresh:
  expected-consumers:
    - "prices-v1"
    - "reference-data-v5"
    - "non-promotable-products"
    - "prices-v4"
    - "minimum-price"
    - "deposit"
    - "product-base-document"
    - "search-product"
    - "location"
    - "location-clusters"
    - "selling-restrictions"
    - "colleague-facts-jobs"
    - "colleague-facts-legacy"
    - "loss-prevention-configuration"
    - "loss-prevention-store-configuration"
    - "loss-prevention-product"
    - "loss-prevention-rule-config"
    - "stored-value-services-banned-promotion"
    - "stored-value-services-active-promotion"
    - "colleague-card-pin"
    - "dcxp-content"
    - "restriction-rules"
    - "dcxp-ugc"

  # Future: service-topic mapping for service-level refresh
  # Uncomment and configure when implementing service-level refresh
  # service-topics:
  #   price-quote-service:
  #     - prices-v1
  #     - prices-v4
  #     - minimum-price
  #     - reference-data-v5

logger:
  levels:
    com.messaging: INFO
    io.netty: WARN
